@software{afl++,
  title = {{{AFL}}++},
  author = {Heuse, Marc and Ei√üfeldt, Heiko and Fioraldi, Andrea and Maier, Dominik},
  date = {2022-01},
  origdate = {2019-05-28T14:29:06Z},
  url = {https://github.com/AFLplusplus/AFLplusplus},
  abstract = {The fuzzer afl++ is afl with community patches, qemu 5.1 upgrade, collision-free coverage, enhanced laf-intel \& redqueen, AFLfast++ power schedules, MOpt mutators, unicorn\_mode, and a lot more!},
  version = {4.00c},
  keywords = {üìú Œ†œÑœÖœáŒπŒ±Œ∫ŒÆ,repo}
}

@inproceedings{afl++paper,
  title = {{{AFL}}++: {{Combining}} Incremental Steps of Fuzzing Research},
  booktitle = {14th {{USENIX}} Workshop on Offensive Technologies ({{WOOT}} 20)},
  author = {Fioraldi, Andrea and Maier, Dominik and Ei√üfeldt, Heiko and Heuse, Marc},
  date = {2020-08},
  publisher = {USENIX Association},
  keywords = {üìú Œ†œÑœÖœáŒπŒ±Œ∫ŒÆ,suggested},
  file = {/home/kchou/HDD/Library/References/Fioraldi et al. - 2020 - AFL++ Combining incremental steps of fuzzing research - @AFLplusplus-Woot20.pdf}
}

@software{atheris,
  title = {Google/Atheris},
  date = {2025-04-09T10:53:48Z},
  origdate = {2020-11-16T22:43:28Z},
  url = {https://github.com/google/atheris},
  organization = {Google},
  keywords = {üìú Œ†œÑœÖœáŒπŒ±Œ∫ŒÆ,repo}
}

@online{chainofthought,
  title = {Chain-of-{{Thought Prompting Elicits Reasoning}} in {{Large Language Models}}},
  author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc and Zhou, Denny},
  date = {2023-01-10},
  eprint = {2201.11903},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2201.11903},
  url = {http://arxiv.org/abs/2201.11903},
  abstract = {We explore how generating a chain of thought -- a series of intermediate reasoning steps -- significantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufficiently large language models via a simple method called chain of thought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting. Experiments on three large language models show that chain of thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a 540B-parameter language model with just eight chain of thought exemplars achieves state of the art accuracy on the GSM8K benchmark of math word problems, surpassing even finetuned GPT-3 with a verifier.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,llm,prompting},
  file = {/home/kchou/HDD/Library/References/Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models - wei2023.pdf}
}

@online{dspy,
  title = {{{DSPy}}: {{Compiling Declarative Language Model Calls}} into {{Self-Improving Pipelines}}},
  shorttitle = {{{DSPy}}},
  author = {Khattab, Omar and Singhvi, Arnav and Maheshwari, Paridhi and Zhang, Zhiyuan and Santhanam, Keshav and Vardhamanan, Sri and Haq, Saiful and Sharma, Ashutosh and Joshi, Thomas T. and Moazam, Hanna and Miller, Heather and Zaharia, Matei and Potts, Christopher},
  date = {2023-10-05},
  eprint = {2310.03714},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2310.03714},
  url = {http://arxiv.org/abs/2310.03714},
  abstract = {The ML community is rapidly exploring techniques for prompting language models (LMs) and for stacking them into pipelines that solve complex tasks. Unfortunately, existing LM pipelines are typically implemented using hard-coded "prompt templates", i.e. lengthy strings discovered via trial and error. Toward a more systematic approach for developing and optimizing LM pipelines, we introduce DSPy, a programming model that abstracts LM pipelines as text transformation graphs, i.e. imperative computational graphs where LMs are invoked through declarative modules. DSPy modules are parameterized, meaning they can learn (by creating and collecting demonstrations) how to apply compositions of prompting, finetuning, augmentation, and reasoning techniques. We design a compiler that will optimize any DSPy pipeline to maximize a given metric. We conduct two case studies, showing that succinct DSPy programs can express and optimize sophisticated LM pipelines that reason about math word problems, tackle multi-hop retrieval, answer complex questions, and control agent loops. Within minutes of compiling, a few lines of DSPy allow GPT-3.5 and llama2-13b-chat to self-bootstrap pipelines that outperform standard few-shot prompting (generally by over 25\% and 65\%, respectively) and pipelines with expert-created demonstrations (by up to 5-46\% and 16-40\%, respectively). On top of that, DSPy programs compiled to open and relatively small LMs like 770M-parameter T5 and llama2-13b-chat are competitive with approaches that rely on expert-written prompt chains for proprietary GPT-3.5. DSPy is available at https://github.com/stanfordnlp/dspy},
  pubstate = {prepublished},
  keywords = {üìú Œ†œÑœÖœáŒπŒ±Œ∫ŒÆ,Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Information Retrieval,Computer Science - Machine Learning},
  file = {/home/kchou/HDD/Library/References/Khattab et al. - 2023 - DSPy Compiling Declarative Language Model Calls into Self-Improving Pipelines - @khattabDSPyCompilingDeclarative2023.pdf;/home/kchou/HDD/Library/References/2310.html}
}

@inproceedings{fudge,
  title = {{{FUDGE}}: Fuzz Driver Generation at Scale},
  shorttitle = {{{FUDGE}}},
  booktitle = {Proceedings of the 2019 27th {{ACM Joint Meeting}} on {{European Software Engineering Conference}} and {{Symposium}} on the {{Foundations}} of {{Software Engineering}}},
  author = {Babiƒá, Domagoj and Bucur, Stefan and Chen, Yaohui and Ivanƒçiƒá, Franjo and King, Tim and Kusano, Markus and Lemieux, Caroline and Szekeres, L√°szl√≥ and Wang, Wei},
  date = {2019-08-12},
  pages = {975--985},
  publisher = {ACM},
  location = {Tallinn Estonia},
  doi = {10.1145/3338906.3340456},
  url = {https://dl.acm.org/doi/10.1145/3338906.3340456},
  eventtitle = {{{ESEC}}/{{FSE}} '19: 27th {{ACM Joint European Software Engineering Conference}} and {{Symposium}} on the {{Foundations}} of {{Software Engineering}}},
  isbn = {978-1-4503-5572-8},
  langid = {english},
  keywords = {üìú Œ†œÑœÖœáŒπŒ±Œ∫ŒÆ},
  annotation = {Read\_Status: To Read\\
Read\_Status\_Date: 2025-05-04T14:28:48.237Z},
  file = {/home/kchou/HDD/Library/Zotero data/storage/VMLR5CAA/Babiƒá et al. - 2019 - FUDGE fuzz driver generation at scale - @babicFUDGEFuzzDriver2019.pdf}
}

@inproceedings{fuzzgen,
  title = {{{FuzzGen}}: {{Automatic}} Fuzzer Generation},
  shorttitle = {\{\vphantom\}{{FuzzGen}}\vphantom\{\}},
  booktitle = {29th {{USENIX Security Symposium}} ({{USENIX Security}} 20)},
  author = {Ispoglou, Kyriakos and Austin, Daniel and Mohan, Vishwath and Payer, Mathias},
  date = {2020},
  pages = {2271--2287},
  url = {https://www.usenix.org/conference/usenixsecurity20/presentation/ispoglou},
  keywords = {fuzzing},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-05-09T15:42:23.379Z},
  file = {/home/kchou/HDD/Library/References/Ispoglou et al. - 2020 - FuzzGen Automatic fuzzer generation - ispoglou2020.pdf}
}

@online{fuzzgpt,
  title = {Large {{Language Models}} Are {{Edge-Case Fuzzers}}: {{Testing Deep Learning Libraries}} via {{FuzzGPT}}},
  shorttitle = {Large {{Language Models}} Are {{Edge-Case Fuzzers}}},
  author = {Deng, Yinlin and Xia, Chunqiu Steven and Yang, Chenyuan and Zhang, Shizhuo Dylan and Yang, Shujing and Zhang, Lingming},
  date = {2023-04-04},
  eprint = {2304.02014},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2304.02014},
  url = {http://arxiv.org/abs/2304.02014},
  abstract = {Bugs in Deep Learning (DL) libraries may affect almost all downstream DL applications, and it is crucial to ensure the quality of such systems. It is challenging to generate valid input programs for fuzzing DL libraries, since the input programs need to satisfy both the syntax/semantics of the supported languages (e.g., Python) and the tensor/operator constraints for constructing valid computational graphs. Recently, the TitanFuzz work demonstrates that modern Large Language Models (LLMs) can be directly leveraged to implicitly learn all the language and DL computation constraints to generate valid programs for fuzzing DL libraries. However, LLMs tend to generate ordinary programs following similar patterns/tokens with typical programs seen in their massive training corpora (e.g., GitHub), while fuzzing favors unusual inputs that cover edge cases or are unlikely to be manually produced. To fill this gap, this paper proposes FuzzGPT, the first technique to prime LLMs to synthesize unusual programs for fuzzing. FuzzGPT is built on the well-known hypothesis that historical bug-triggering programs may include rare/valuable code ingredients important for bug finding. Meanwhile, while traditional techniques leveraging such historical information require intensive human efforts to both design dedicated generators and ensure the syntactic/semantic validity of generated programs, FuzzGPT demonstrates that this process can be fully automated via the intrinsic capabilities of LLMs (including fine-tuning and in-context learning), while being generalizable and applicable to challenging domains. While FuzzGPT can be applied with different LLMs, this paper focuses on the powerful GPT-style models: Codex and CodeGen. Moreover, FuzzGPT also shows the potential of directly leveraging the instruct-following capability of the recent ChatGPT for effective fuzzing. The experimental study on two popular DL libraries (PyTorch and TensorFlow) shows that FuzzGPT can substantially outperform TitanFuzz, detecting 76 bugs, with 49 already confirmed as previously unknown bugs, including 11 high-priority bugs or security vulnerabilities.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Software Engineering},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-05-08T13:33:14.524Z},
  file = {/home/kchou/HDD/Library/References/Deng et al. - 2023 - Large Language Models are Edge-Case Fuzzers Testing Deep Learning Libraries via FuzzGPT - deng2023.pdf}
}

@online{gao2024,
  title = {Retrieval-{{Augmented Generation}} for {{Large Language Models}}: {{A Survey}}},
  shorttitle = {Retrieval-{{Augmented Generation}} for {{Large Language Models}}},
  author = {Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jia, Kangxiang and Pan, Jinliu and Bi, Yuxi and Dai, Yi and Sun, Jiawei and Wang, Meng and Wang, Haofen},
  date = {2024-03-27},
  eprint = {2312.10997},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2312.10997},
  url = {http://arxiv.org/abs/2312.10997},
  abstract = {Large Language Models (LLMs) showcase impressive capabilities but encounter challenges like hallucination, outdated knowledge, and non-transparent, untraceable reasoning processes. Retrieval-Augmented Generation (RAG) has emerged as a promising solution by incorporating knowledge from external databases. This enhances the accuracy and credibility of the generation, particularly for knowledge-intensive tasks, and allows for continuous knowledge updates and integration of domain-specific information. RAG synergistically merges LLMs' intrinsic knowledge with the vast, dynamic repositories of external databases. This comprehensive review paper offers a detailed examination of the progression of RAG paradigms, encompassing the Naive RAG, the Advanced RAG, and the Modular RAG. It meticulously scrutinizes the tripartite foundation of RAG frameworks, which includes the retrieval, the generation and the augmentation techniques. The paper highlights the state-of-the-art technologies embedded in each of these critical components, providing a profound understanding of the advancements in RAG systems. Furthermore, this paper introduces up-to-date evaluation framework and benchmark. At the end, this article delineates the challenges currently faced and points out prospective avenues for research and development.},
  pubstate = {prepublished},
  keywords = {üìú Œ†œÑœÖœáŒπŒ±Œ∫ŒÆ,Computer Science - Artificial Intelligence,Computer Science - Computation and Language,RAG},
  file = {/home/kchou/HDD/Documents/Zotero Library/Gao et al. - 2024 - Retrieval-Augmented Generation for Large Language Models A Survey - @gaoRetrievalAugmentedGenerationLarge2024.pdf;/home/kchou/HDD/Documents/Zotero Library/2312 2.html}
}

@online{heartbleed,
  title = {Heartbleed {{Bug}}},
  url = {https://heartbleed.com/},
  keywords = {üìú Œ†œÑœÖœáŒπŒ±Œ∫ŒÆ},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-05-04T14:28:15.555Z},
  file = {/home/kchou/HDD/Library/References/heartbleed.com.html}
}

@online{iris,
  title = {{{IRIS}}: {{LLM-Assisted Static Analysis}} for {{Detecting Security Vulnerabilities}}},
  shorttitle = {{{IRIS}}},
  author = {Li, Ziyang and Dutta, Saikat and Naik, Mayur},
  date = {2025-04-06},
  eprint = {2405.17238},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2405.17238},
  url = {http://arxiv.org/abs/2405.17238},
  abstract = {Software is prone to security vulnerabilities. Program analysis tools to detect them have limited effectiveness in practice due to their reliance on human labeled specifications. Large language models (or LLMs) have shown impressive code generation capabilities but they cannot do complex reasoning over code to detect such vulnerabilities especially since this task requires whole-repository analysis. We propose IRIS, a neuro-symbolic approach that systematically combines LLMs with static analysis to perform whole-repository reasoning for security vulnerability detection. Specifically, IRIS leverages LLMs to infer taint specifications and perform contextual analysis, alleviating needs for human specifications and inspection. For evaluation, we curate a new dataset, CWE-Bench-Java, comprising 120 manually validated security vulnerabilities in real-world Java projects. A state-of-the-art static analysis tool CodeQL detects only 27 of these vulnerabilities whereas IRIS with GPT-4 detects 55 (+28) and improves upon CodeQL's average false discovery rate by 5\% points. Furthermore, IRIS identifies 4 previously unknown vulnerabilities which cannot be found by existing tools. IRIS is available publicly at https://github.com/iris-sast/iris.},
  pubstate = {prepublished},
  keywords = {üìú Œ†œÑœÖœáŒπŒ±Œ∫ŒÆ,Computer Science - Cryptography and Security,Computer Science - Programming Languages,Computer Science - Software Engineering,llm fuzzing},
  annotation = {Read\_Status: To Read\\
Read\_Status\_Date: 2025-05-05T11:45:47.764Z},
  file = {/home/kchou/HDD/Library/References/Li et al. - 2025 - IRIS LLM-Assisted Static Analysis for Detecting Security Vulnerabilities - @liIRISLLMAssistedStatic2025.pdf;/home/kchou/HDD/Library/References/2405 2.html}
}

@inproceedings{klee,
  title = {{{KLEE}}: {{Unassisted}} and {{Automatic Generation}} of {{High-Coverage Tests}} for {{Complex Systems Programs}}},
  shorttitle = {{{KLEE}}},
  author = {Cadar, Cristian and Dunbar, Daniel and Engler, D.},
  date = {2008-12-08},
  url = {https://www.semanticscholar.org/paper/KLEE%3A-Unassisted-and-Automatic-Generation-of-Tests-Cadar-Dunbar/0b93657965e506dfbd56fbc1c1d4b9666b1d01c8},
  abstract = {We present a new symbolic execution tool, KLEE, capable of automatically generating tests that achieve high coverage on a diverse set of complex and environmentally-intensive programs. We used KLEE to thoroughly check all 89 stand-alone programs in the GNU COREUTILS utility suite, which form the core user-level environment installed on millions of Unix systems, and arguably are the single most heavily tested set of open-source programs in existence. KLEE-generated tests achieve high line coverage -- on average over 90\% per tool (median: over 94\%) -- and significantly beat the coverage of the developers' own hand-written test suite. When we did the same for 75 equivalent tools in the BUSYBOX embedded system suite, results were even better, including 100\% coverage on 31 of them.    We also used KLEE as a bug finding tool, applying it to 452 applications (over 430K total lines of code), where it found 56 serious bugs, including three in COREUTILS that had been missed for over 15 years. Finally, we used KLEE to crosscheck purportedly identical BUSYBOX and COREUTILS utilities, finding functional correctness errors and a myriad of inconsistencies.},
  eventtitle = {{{USENIX Symposium}} on {{Operating Systems Design}} and {{Implementation}}},
  keywords = {üìú Œ†œÑœÖœáŒπŒ±Œ∫ŒÆ,suggested},
  annotation = {Read\_Status: To Read\\
Read\_Status\_Date: 2025-03-19T10:38:46.368Z},
  file = {/home/kchou/HDD/Library/References/Cadar et al. - 2008 - KLEE Unassisted and Automatic Generation of High-Coverage Tests for Complex Systems Programs - @cadarKLEEUnassistedAutomatic2008.pdf}
}

@online{libfuzzer,
  title = {{{libFuzzer}} ‚Äì a Library for Coverage-Guided Fuzz Testing. ‚Äî {{LLVM}} 21.0.0git Documentation},
  url = {https://llvm.org/docs/LibFuzzer.html},
  keywords = {üìú Œ†œÑœÖœáŒπŒ±Œ∫ŒÆ},
  file = {/home/kchou/HDD/Library/References/LibFuzzer.html}
}

@online{manes2019,
  title = {The {{Art}}, {{Science}}, and {{Engineering}} of {{Fuzzing}}: {{A Survey}}},
  shorttitle = {The {{Art}}, {{Science}}, and {{Engineering}} of {{Fuzzing}}},
  author = {Manes, Valentin J. M. and Han, HyungSeok and Han, Choongwoo and Cha, Sang Kil and Egele, Manuel and Schwartz, Edward J. and Woo, Maverick},
  date = {2019-04-07},
  eprint = {1812.00140},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1812.00140},
  url = {http://arxiv.org/abs/1812.00140},
  abstract = {Among the many software vulnerability discovery techniques available today, fuzzing has remained highly popular due to its conceptual simplicity, its low barrier to deployment, and its vast amount of empirical evidence in discovering real-world software vulnerabilities. At a high level, fuzzing refers to a process of repeatedly running a program with generated inputs that may be syntactically or semantically malformed. While researchers and practitioners alike have invested a large and diverse effort towards improving fuzzing in recent years, this surge of work has also made it difficult to gain a comprehensive and coherent view of fuzzing. To help preserve and bring coherence to the vast literature of fuzzing, this paper presents a unified, general-purpose model of fuzzing together with a taxonomy of the current fuzzing literature. We methodically explore the design decisions at every stage of our model fuzzer by surveying the related literature and innovations in the art, science, and engineering that make modern-day fuzzers effective.},
  pubstate = {prepublished},
  keywords = {üìú Œ†œÑœÖœáŒπŒ±Œ∫ŒÆ,suggested},
  annotation = {Read\_Status: In Progress\\
Read\_Status\_Date: 2024-10-19T09:03:55.881Z},
  file = {/home/kchou/HDD/Documents/Zotero Library/Manes et al. - 2019 - The Art, Science, and Engineering of Fuzzing A Survey - @manesArtScienceEngineering2019.pdf;/home/kchou/HDD/Documents/Zotero Library/1812.html}
}

@software{oss-fuzz,
  title = {{{OSS-Fuzz}}},
  author = {Arya, Abhishek and Chang, Oliver and Metzman, Jonathan and Serebryany, Kostya and Liu, Dongge},
  date = {2025-04-08T14:23:14Z},
  origdate = {2016-07-20T19:39:50Z},
  url = {https://github.com/google/oss-fuzz},
  abstract = {OSS-Fuzz - continuous fuzzing for open source software.},
  keywords = {üìú Œ†œÑœÖœáŒπŒ±Œ∫ŒÆ,repo}
}

@software{oss-fuzz-gen,
  title = {{{OSS-fuzz-gen}}: {{Automated}} Fuzz Target Generation},
  author = {Liu, Dongge and Chang, Oliver and {metzman}, Jonathan and Sablotny, Martin and Maruseac, Mihai},
  date = {2024-05},
  url = {https://github.com/google/oss-fuzz-gen},
  version = {https://github.com/google/oss-fuzz-gen/tree/v1.0},
  keywords = {üìú Œ†œÑœÖœáŒπŒ±Œ∫ŒÆ,repo}
}

@online{oss-fuzzmaintainers2024,
  title = {Introducing {{LLM-based}} Harness Synthesis for Unfuzzed Projects},
  author = {{OSS-Fuzz Maintainers}},
  date = {2024-05-27T00:00:00+00:00},
  url = {https://blog.oss-fuzz.com/posts/introducing-llm-based-harness-synthesis-for-unfuzzed-projects/},
  abstract = {The primary goal of our efforts are to take as input a GitHub repository and output an OSS-Fuzz project as well as a ClusterFuzzLite project with a meaningful fuzz harness. In this blog post we will describe how we automatically build projects, how we generate fuzzing harnesses using LLMs, how these are evaluated and list a selection of 15 projects that we generated OSS-Fuzz/ClusterFuzzLite integrations for and have upstreamed the results. Introducing LLM-based harness generation for unfuzzed projects.},
  langid = {english},
  organization = {OSS-Fuzz blog},
  keywords = {üìú Œ†œÑœÖœáŒπŒ±Œ∫ŒÆ,important,with-notes},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-04-01T09:51:26.317Z},
  file = {/home/kchou/HDD/Library/References/index.html}
}

@online{prophetfuzz,
  title = {{{ProphetFuzz}}: {{Fully Automated Prediction}} and {{Fuzzing}} of {{High-Risk Option Combinations}} with {{Only Documentation}} via {{Large Language Model}}},
  shorttitle = {{{ProphetFuzz}}},
  author = {Wang, Dawei and Zhou, Geng and Chen, Li and Li, Dan and Miao, Yukai},
  date = {2024-09-01},
  eprint = {2409.00922},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.1145/3658644.3690231},
  url = {http://arxiv.org/abs/2409.00922},
  abstract = {Vulnerabilities related to option combinations pose a significant challenge in software security testing due to their vast search space. Previous research primarily addressed this challenge through mutation or filtering techniques, which inefficiently treated all option combinations as having equal potential for vulnerabilities, thus wasting considerable time on non-vulnerable targets and resulting in low testing efficiency. In this paper, we utilize carefully designed prompt engineering to drive the large language model (LLM) to predict high-risk option combinations (i.e., more likely to contain vulnerabilities) and perform fuzz testing automatically without human intervention. We developed a tool called ProphetFuzz and evaluated it on a dataset comprising 52 programs collected from three related studies. The entire experiment consumed 10.44 CPU years. ProphetFuzz successfully predicted 1748 high-risk option combinations at an average cost of only \textbackslash\$8.69 per program. Results show that after 72 hours of fuzzing, ProphetFuzz discovered 364 unique vulnerabilities associated with 12.30\textbackslash\% of the predicted high-risk option combinations, which was 32.85\textbackslash\% higher than that found by state-of-the-art in the same timeframe. Additionally, using ProphetFuzz, we conducted persistent fuzzing on the latest versions of these programs, uncovering 140 vulnerabilities, with 93 confirmed by developers and 21 awarded CVE numbers.},
  pubstate = {prepublished},
  keywords = {üìú Œ†œÑœÖœáŒπŒ±Œ∫ŒÆ},
  annotation = {Read\_Status: To Read\\
Read\_Status\_Date: 2024-10-19T08:53:01.845Z},
  file = {/home/kchou/HDD/Library/References/Wang et al. - 2024 - ProphetFuzz Fully Automated Prediction and Fuzzing of High-Risk Option Combinations with Only Docum - @wangProphetFuzzFullyAutomated2024.pdf;/home/kchou/HDD/Library/References/2409.html}
}

@online{pytorch,
  title = {{{PyTorch}}: {{An Imperative Style}}, {{High-Performance Deep Learning Library}}},
  shorttitle = {{{PyTorch}}},
  author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and K√∂pf, Andreas and Yang, Edward and DeVito, Zach and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
  date = {2019-12-03},
  eprint = {1912.01703},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1912.01703},
  url = {http://arxiv.org/abs/1912.01703},
  abstract = {Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it provides an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs. In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several common benchmarks.},
  pubstate = {prepublished},
  file = {/home/kchou/HDD/Library/References/Paszke et al_2019_PyTorch.pdf;/home/kchou/HDD/Library/Zotero data/storage/6MM7VAXX/1912.html}
}

@online{reAct,
  title = {{{ReAct}}: {{Synergizing Reasoning}} and {{Acting}} in {{Language Models}}},
  shorttitle = {{{ReAct}}},
  author = {Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  date = {2023-03-10},
  eprint = {2210.03629},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2210.03629},
  url = {http://arxiv.org/abs/2210.03629},
  abstract = {While large language models (LLMs) have demonstrated impressive capabilities across tasks in language understanding and interactive decision making, their abilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g. action plan generation) have primarily been studied as separate topics. In this paper, we explore the use of LLMs to generate both reasoning traces and task-specific actions in an interleaved manner, allowing for greater synergy between the two: reasoning traces help the model induce, track, and update action plans as well as handle exceptions, while actions allow it to interface with external sources, such as knowledge bases or environments, to gather additional information. We apply our approach, named ReAct, to a diverse set of language and decision making tasks and demonstrate its effectiveness over state-of-the-art baselines, as well as improved human interpretability and trustworthiness over methods without reasoning or acting components. Concretely, on question answering (HotpotQA) and fact verification (Fever), ReAct overcomes issues of hallucination and error propagation prevalent in chain-of-thought reasoning by interacting with a simple Wikipedia API, and generates human-like task-solving trajectories that are more interpretable than baselines without reasoning traces. On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34\% and 10\% respectively, while being prompted with only one or two in-context examples. Project site with code: https://react-lm.github.io},
  pubstate = {prepublished},
  keywords = {üìú Œ†œÑœÖœáŒπŒ±Œ∫ŒÆ},
  annotation = {Read\_Status: To Read\\
Read\_Status\_Date: 2024-10-21T16:44:45.166Z},
  file = {/home/kchou/HDD/Library/References/Yao et al. - 2023 - ReAct Synergizing Reasoning and Acting in Language Models - @yaoReActSynergizingReasoning2023.pdf;/home/kchou/HDD/Library/References/2210.html}
}

@software{tensorflow,
  title = {{{TensorFlow}}, {{Large-scale}} Machine Learning on Heterogeneous Systems},
  author = {Abadi, Mart√≠n and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and Corrado, Greg S. and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Goodfellow, Ian and Harp, Andrew and Irving, Geoffrey and Isard, Michael and Jozefowicz, Rafal and Jia, Yangqing and Kaiser, Lukasz and Kudlur, Manjunath and Levenberg, Josh and Man√©, Dan and Schuster, Mike and Monga, Rajat and Moore, Sherry and Murray, Derek and Olah, Chris and Shlens, Jonathon and Steiner, Benoit and Sutskever, Ilya and Talwar, Kunal and Tucker, Paul and Vanhoucke, Vincent and Vasudevan, Vijay and Vi√©gas, Fernanda and Vinyals, Oriol and Warden, Pete and Wattenberg, Martin and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
  date = {2015-11},
  doi = {10.5281/zenodo.4724125}
}

@inproceedings{titanfuzz,
  title = {Large {{Language Models Are Zero-Shot Fuzzers}}: {{Fuzzing Deep-Learning Libraries}} via {{Large Language Models}}},
  shorttitle = {Large {{Language Models Are Zero-Shot Fuzzers}}},
  booktitle = {Proceedings of the 32nd {{ACM SIGSOFT International Symposium}} on {{Software Testing}} and {{Analysis}}},
  author = {Deng, Yinlin and Xia, Chunqiu Steven and Peng, Haoran and Yang, Chenyuan and Zhang, Lingming},
  date = {2023-07-13},
  series = {{{ISSTA}} 2023},
  pages = {423--435},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3597926.3598067},
  url = {https://dl.acm.org/doi/10.1145/3597926.3598067},
  abstract = {Deep Learning (DL) systems have received exponential growth in popularity and have become ubiquitous in our everyday life. Such systems are built on top of popular DL libraries, e.g., TensorFlow and PyTorch which provide APIs as building blocks for DL systems. Detecting bugs in these DL libraries is critical for almost all downstream DL systems in ensuring effectiveness/safety for end users. Meanwhile, traditional fuzzing techniques can be hardly effective for such a challenging domain since the input DL programs need to satisfy both the input language (e.g., Python) syntax/semantics and the DL API input/shape constraints for tensor computations.   To address these limitations, we propose TitanFuzz ‚Äì the first approach to directly leveraging Large Language Models (LLMs) to generate input programs for fuzzing DL libraries. LLMs are titanic models trained on billions of code snippets and can autoregressively generate human-like code snippets. Our key insight is that modern LLMs can also include numerous code snippets invoking DL library APIs in their training corpora, and thus can implicitly learn both language syntax/semantics and intricate DL API constraints for valid DL program generation. More specifically, we use both generative and infilling LLMs (e.g., Codex/InCoder) to generate and mutate valid/diverse input DL programs for fuzzing. Our experimental results demonstrate that TitanFuzz can achieve 30.38\%/50.84\% higher code coverage than state-of-the-art fuzzers on TensorFlow/PyTorch. Furthermore, TitanFuzz is able to detect 65 bugs, with 44 already confirmed as previously unknown bugs.   This paper demonstrates that modern titanic LLMs can be leveraged to directly perform both generation-based and mutation-based fuzzing studied for decades, while being fully automated, generalizable, and applicable to domains challenging for traditional approaches (such as DL systems). We hope TitanFuzz can stimulate more work in this promising direction of LLMs for fuzzing.},
  isbn = {979-8-4007-0221-1},
  keywords = {üìú Œ†œÑœÖœáŒπŒ±Œ∫ŒÆ},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-05-06T12:49:07.180Z},
  file = {/home/kchou/HDD/Library/References/Deng et al. - 2023 - Large Language Models Are Zero-Shot Fuzzers Fuzzing Deep-Learning Libraries via Large Language Mode - @dengLargeLanguageModels2023.pdf}
}

@online{zotero-item-4182,
  title = {{{AI-Powered Fuzzing}}: {{Breaking}} the {{Bug Hunting Barrier}}},
  shorttitle = {{{AI-Powered Fuzzing}}},
  url = {https://security.googleblog.com/2023/08/ai-powered-fuzzing-breaking-bug-hunting.html},
  abstract = {Dongge Liu, Jonathan Metzman, Oliver Chang, Google Open Source Security Team~ Since 2016, OSS-Fuzz  has been at the forefront of automated v...},
  langid = {english},
  organization = {Google Online Security Blog},
  keywords = {üìú Œ†œÑœÖœáŒπŒ±Œ∫ŒÆ},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-05-04T14:27:49.683Z},
  file = {/home/kchou/HDD/Documents/Zotero Library/ai-powered-fuzzing-breaking-bug-hunting.html}
}

@online{zotero-item-4392,
  title = {{{OSS-Fuzz Documentation}}},
  url = {https://google.github.io/oss-fuzz/},
  abstract = {Documentation for OSS-Fuzz},
  langid = {american},
  organization = {OSS-Fuzz},
  keywords = {üìú Œ†œÑœÖœáŒπŒ±Œ∫ŒÆ},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-05-04T14:28:02.098Z},
  file = {/home/kchou/HDD/Library/References/oss-fuzz.html}
}
